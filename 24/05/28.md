# RAG 自動評価「RAGAS」について

一番参考になった記事

- https://qiita.com/warper/items/6b71e6b0325ac23039c4

うまくいかず、参考にした記事

- https://qiita.com/nakano-m/items/6ad26e3a14fe4e415d0a

# 環境構築

Lambda で動かしたかったが、うまくいかなかった。  
時間がかかるので、ローカルで動かすことにした。

RAGAS のインストール

```
pip install ragas
```

サンプルソース

```
import os

os.environ['OPENAI_API_KEY'] = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'

from datasets import Dataset

from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy, context_recall, context_precision, context_utilization, answer_similarity, answer_correctness


data_samples = {
    'question': ['When was the first super bowl?', 'Who won the most super bowls?'],
    'answer': ['The first superbowl was held on Jan 15, 1967', 'The most super bowls have been won by The New England Patriots'],
    'contexts' : [['The First AFL–NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles,'],
    ['The Green Bay Packers...Green Bay, Wisconsin.','The Packers compete...Football Conference']],
    'ground_truth': ['The first superbowl was held on January 15, 1967', 'The New England Patriots have won the Super Bowl a record six times']
}


dataset = Dataset.from_dict(data_samples)

# 評価
result = evaluate(dataset, [ faithfulness, answer_relevancy, context_recall, context_precision, context_utilization, answer_similarity, answer_correctness])
print(result)

```

#　結果

実行してみると、実行するたびに結果が変わる。  
特に、faithfulness は、0 になったり、1 になったり、0.5 になったり安定しない。  
各指標の意味を理解したら、なんでそうなるかわかった。  
指標として使うのは、Answer Correctness と answer_similarity だけでいいかもしれない。

# Faithfulness

## RAGAS フレームワークにおける信頼性（Faithfulness）の計算方法

RAGAS フレームワークでは、生成された回答が与えられた文脈にどれだけ忠実であるか（Faithfulness）を評価します。以下にその具体的な手順を説明します。

### 信頼性（Faithfulness）の計算方法

1. **ステートメントの抽出**:

   - まず、LLM（大規模言語モデル）を使用して、生成された回答から複数のステートメント（命題）を抽出します。これは、長い文をより短く焦点を絞った命題に分解するためのものです。
   - 使用するプロンプトの例：
     ```
     Given a question and answer, create one or more statements from each sentence in the given answer.
     question: [question]
     answer: [answer]
     ```
   - このプロンプトを使って、回答を短い命題に分解します。

2. **ステートメントの検証**:

   - 次に、LLM を使用して各命題が文脈から導き出せるかどうかを検証します。これには以下のプロンプトを使用します：
     ```
     Consider the given context and following statements, then determine whether they are supported by the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format.
     statement: [statement 1]
     ...
     statement: [statement n]
     ```
   - LLM が各命題について「Yes」または「No」の判定を行い、その判定が支持される理由を簡潔に説明します。

3. **信頼性スコアの算出**:
   - 最終的な信頼性スコア \( F \) は、支持されたステートメントの数 \( |V| \) を全ステートメントの数 \( |S| \) で割ったものとして計算されます。
   - 数式で表すと、次のようになります：
     信頼性スコア \( F = |V| ÷ |S| \)
   - ここで、 \( |V| \) は支持されたステートメントの数、 \( |S| \) は全ステートメントの数です。

### 具体例

例えば、質問と回答が以下のような場合を考えます：

- 質問: 「映画『オッペンハイマー』の監督は誰で、J・ロバート・オッペンハイマー役を演じたのは誰ですか？」
- 回答: 「クリストファー・ノーランが映画『オッペンハイマー』を監督しました。キリアン・マーフィーが J・ロバート・オッペンハイマーを演じています。」

この回答から次のようなステートメントを抽出します：

1. 「クリストファー・ノーランが映画『オッペンハイマー』を監督しました。」
2. 「キリアン・マーフィーが J・ロバート・オッペンハイマーを演じています。」

次に、文脈が以下のようなものであるとします：

- 文脈: 「『オッペンハイマー』は 2023 年の伝記スリラー映画で、クリストファー・ノーランが脚本・監督を務めています。カイ・バードとマーティン・J・シャーウィンによる 2005 年の伝記『アメリカン・プロメテウス』に基づいており、理論物理学者 J・ロバート・オッペンハイマーの人生を描いています。オッペンハイマーはマンハッタン計画の一環として最初の核兵器の開発に重要な役割を果たし、それにより原子力時代をもたらしました。キリアン・マーフィーがオッペンハイマーを演じ、エミリー・ブラントがオッペンハイマーの妻キャサリン『キティ』・オッペンハイマーを演じています。」

この文脈を元に、各ステートメントを検証します：

1. 「クリストファー・ノーランが映画『オッペンハイマー』を監督しました。」 - Yes
2. 「キリアン・マーフィーが J・ロバート・オッペンハイマーを演じています。」 - Yes

この場合、支持されたステートメントの数 \( |V| = 2 \)、全ステートメントの数 \( |S| = 2 \) なので、信頼性スコア \( F \) は 1.0 になります。

以上が、RAGAS フレームワークにおける信頼性（Faithfulness）の計算方法です。この方法を用いることで、生成された回答が与えられた文脈にどれだけ忠実であるかを定量的に評価することができます。

# Answer Relevancy

## RAGAS フレームワークにおける回答の関連性（Answer Relevancy）の計算方法

RAGAS フレームワークでは、生成された回答が質問にどれだけ関連しているか（Answer Relevancy）を評価します。以下にその具体的な手順を説明します。

### 回答の関連性（Answer Relevancy）の計算方法

1. **質問の生成**:

   - まず、生成された回答から LLM（大規模言語モデル）を使用して、いくつかの潜在的な質問を生成します。
   - 使用するプロンプトの例：
     ```
     Generate a question for the given answer.
     answer: [answer]
     ```
   - このプロンプトを使用して、生成された回答に基づいた複数の質問 \( q_i \) を生成します。

2. **埋め込みの取得**:

   - 次に、生成された質問と元の質問の埋め込みベクトルを取得します。これには、OpenAI の API から利用可能な `text-embedding-ada-002` モデルなどを使用します。

3. **類似度の計算**:

   - 各生成された質問 \( q_i \) と元の質問 \( q \) との類似度を計算します。この類似度は、対応する埋め込みベクトル間のコサイン類似度として計算されます。

4. **回答関連性スコアの算出**:
   - 最終的な回答関連性スコア (AR) は、生成された全ての質問との類似度の平均として計算されます。
   - 数式で表すと、次のようになります：
     回答関連性スコア (AR) = (すべての類似度の合計) ÷ (生成された質問の数)

### 具体例

例えば、質問と回答が以下のような場合を考えます：

- 質問: 「映画『オッペンハイマー』の監督は誰で、J・ロバート・オッペンハイマー役を演じたのは誰ですか？」
- 回答: 「クリストファー・ノーランが映画『オッペンハイマー』を監督しました。キリアン・マーフィーが J・ロバート・オッペンハイマーを演じています。」

この回答から次のような潜在的な質問を生成します：

1. 「映画『オッペンハイマー』の監督は誰ですか？」
2. 「映画『オッペンハイマー』で J・ロバート・オッペンハイマーを演じたのは誰ですか？」

次に、元の質問と生成された各質問の埋め込みベクトルを取得し、それぞれのコサイン類似度を計算します。

例えば、類似度が次のように計算されたとします：

1. 類似度(元の質問, 質問 1) = 0.95
2. 類似度(元の質問, 質問 2) = 0.90

この場合、回答関連性スコア (AR) は次のように計算されます：

回答関連性スコア (AR) = (0.95 + 0.90) ÷ 2 = 0.925

このようにして、回答の関連性を定量的に評価することができます。

以上が、RAGAS フレームワークにおける回答の関連性（Answer Relevancy）の計算方法です。この方法を用いることで、生成された回答が質問にどれだけ適切に関連しているかを評価することができます。

# Answer Semantic Similarity

評価の対象：回答生成モジュール

## RAGAS フレームワークにおける回答の意味的類似性（Answer Semantic Similarity）の計算方法

RAGAS フレームワークでは、生成された回答が元の回答とどれだけ意味的に類似しているか（Answer Semantic Similarity）を評価します。以下にその具体的な手順を説明します。

### 回答の意味的類似性（Answer Semantic Similarity）の計算方法

1. **埋め込みの取得**:

   - まず、生成された回答と元の回答の埋め込みベクトルを取得します。これには、Huggingface の`HuggingfaceEmbeddings`モデルなどを使用します。

2. **正規化**:

   - 各埋め込みベクトルを正規化します。正規化は、ベクトルをそのノルムで割ることで行います。
   - 正規化されたベクトルを取得するために、次のように計算します：
     ```
     embedding_normalized = embedding / norm
     ```

3. **類似度の計算**:

   - 正規化された埋め込みベクトル間のコサイン類似度を計算します。コサイン類似度は、二つのベクトルの内積として計算されます。
   - コサイン類似度を計算するために、次のようにします：
     ```
     similarity = embedding_1_normalized @ embedding_2_normalized.T
     ```

4. **意味的類似性スコアの算出**:
   - 最終的な意味的類似性スコア (SS) は、計算されたコサイン類似度そのものです。
   - 必要に応じて、しきい値を設定し、スコアをバイナリにマッピングすることも可能です。

### 具体例

例えば、元の回答と生成された回答が以下のような場合を考えます：

- 元の回答: 「クリストファー・ノーランが映画『オッペンハイマー』を監督しました。キリアン・マーフィーが J・ロバート・オッペンハイマーを演じています。」
- 生成された回答: 「クリストファー・ノーランが映画『オッペンハイマー』を監督し、キリアン・マーフィーが主演しています。」

この場合、各回答の埋め込みベクトルを取得し、それを正規化します。その後、正規化されたベクトル間のコサイン類似度を計算します。

例えば、類似度が次のように計算されたとします：

1. 元の回答の埋め込みベクトルと生成された回答の埋め込みベクトルの類似度 = 0.95

この場合、回答の意味的類似性スコア (SS) は 0.95 となります。

このようにして、生成された回答が元の回答とどれだけ意味的に類似しているかを定量的に評価することができます。

以上が、RAGAS フレームワークにおける回答の意味的類似性（Answer Semantic Similarity）の計算方法です。この方法を用いることで、生成された回答が元の回答とどれだけ意味的に関連しているかを評価することができます。
