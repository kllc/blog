# RAG 自動評価「RAGAS」について

一番参考になった記事

- https://qiita.com/warper/items/6b71e6b0325ac23039c4

うまくいかず、参考にした記事

- https://qiita.com/nakano-m/items/6ad26e3a14fe4e415d0a

# 環境構築

RAGAS のインストール

```
pip install ragas
```

サンプルソース

```
import os

os.environ['OPENAI_API_KEY'] = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'

from datasets import Dataset

from ragas import evaluate
from ragas.metrics import faithfulness, answer_relevancy, context_recall, context_precision, context_utilization, answer_similarity, answer_correctness


data_samples = {
    'question': ['When was the first super bowl?', 'Who won the most super bowls?'],
    'answer': ['The first superbowl was held on Jan 15, 1967', 'The most super bowls have been won by The New England Patriots'],
    'contexts' : [['The First AFL–NFL World Championship Game was an American football game played on January 15, 1967, at the Los Angeles Memorial Coliseum in Los Angeles,'],
    ['The Green Bay Packers...Green Bay, Wisconsin.','The Packers compete...Football Conference']],
    'ground_truth': ['The first superbowl was held on January 15, 1967', 'The New England Patriots have won the Super Bowl a record six times']
}


dataset = Dataset.from_dict(data_samples)

# 評価
result = evaluate(dataset, [ faithfulness, answer_relevancy, context_recall, context_precision, context_utilization, answer_similarity, answer_correctness])
print(result)

```

# 実行結果と対応

実行してみると、実行するたびに結果が変わり、特に、faithfulness は、0 になったり、1 になったり安定しない。  
0 と 1 では、全く反対の結果なのでこのままでは使えない。  
各指標の意味を理解して、利用する必要がある。

RAGAS のソースに、各指標の python ソースがあるので、それを ChatGPT4o に読んでもらって解説を作成し、どれの指標を利用するか決める。

# Faithfulness

評価の対象：回答生成モジュール

## RAGAS フレームワークにおける信頼性（Faithfulness）の計算方法

RAGAS フレームワークでは、生成された回答が与えられた検索結果にどれだけ忠実であるか（Faithfulness）を評価します。以下にその具体的な手順を説明します。

### 信頼性（Faithfulness）の計算方法

1. **ステートメントの抽出**:

   - まず、LLM（大規模言語モデル）を使用して、生成された回答から複数のステートメント（命題）を抽出します。これは、長い文をより短く焦点を絞った命題に分解するためのものです。
   - 使用するプロンプトの例：
     ```
     Given a question and answer, create one or more statements from each sentence in the given answer.
     question: [question]
     answer: [answer]
     ```
   - このプロンプトを使って、回答を短い命題に分解します。

2. **ステートメントの検証**:

   - 次に、LLM を使用して各命題が検索結果から導き出せるかどうかを検証します。これには以下のプロンプトを使用します：
     ```
     Consider the given context and following statements, then determine whether they are supported by the information present in the context. Provide a brief explanation for each statement before arriving at the verdict (Yes/No). Provide a final verdict for each statement in order at the end in the given format. Do not deviate from the specified format.
     statement: [statement 1]
     ...
     statement: [statement n]
     ```
   - LLM が各命題について「Yes」または「No」の判定を行い、その判定が支持される理由を簡潔に説明します。

3. **信頼性スコアの算出**:
   - 最終的な信頼性スコア \( F \) は、支持されたステートメントの数 \( |V| \) を全ステートメントの数 \( |S| \) で割ったものとして計算されます。
   - 数式で表すと、次のようになります：
     信頼性スコア \( F = |V| ÷ |S| \)
   - ここで、 \( |V| \) は支持されたステートメントの数、 \( |S| \) は全ステートメントの数です。

### 具体例

例えば、質問と回答が以下のような場合を考えます：

- 質問: 「映画『オッペンハイマー』の監督は誰で、J・ロバート・オッペンハイマー役を演じたのは誰ですか？」
- 回答: 「クリストファー・ノーランが映画『オッペンハイマー』を監督しました。キリアン・マーフィーが J・ロバート・オッペンハイマーを演じています。」

この回答から次のようなステートメントを抽出します：

1. 「クリストファー・ノーランが映画『オッペンハイマー』を監督しました。」
2. 「キリアン・マーフィーが J・ロバート・オッペンハイマーを演じています。」

次に、検索結果が以下のようなものであるとします：

- 検索結果: 「『オッペンハイマー』は 2023 年の伝記スリラー映画で、クリストファー・ノーランが脚本・監督を務めています。カイ・バードとマーティン・J・シャーウィンによる 2005 年の伝記『アメリカン・プロメテウス』に基づいており、理論物理学者 J・ロバート・オッペンハイマーの人生を描いています。オッペンハイマーはマンハッタン計画の一環として最初の核兵器の開発に重要な役割を果たし、それにより原子力時代をもたらしました。キリアン・マーフィーがオッペンハイマーを演じ、エミリー・ブラントがオッペンハイマーの妻キャサリン『キティ』・オッペンハイマーを演じています。」

この検索結果を元に、各ステートメントを検証します：

1. 「クリストファー・ノーランが映画『オッペンハイマー』を監督しました。」 - Yes
2. 「キリアン・マーフィーが J・ロバート・オッペンハイマーを演じています。」 - Yes

この場合、支持されたステートメントの数 \( |V| = 2 \)、全ステートメントの数 \( |S| = 2 \) なので、信頼性スコア \( F \) は 1.0 になります。

以上が、RAGAS フレームワークにおける信頼性（Faithfulness）の計算方法です。この方法を用いることで、生成された回答が与えられた検索結果にどれだけ忠実であるかを定量的に評価することができます。

# Answer Relevancy

評価の対象：回答生成モジュール

## RAGAS フレームワークにおける回答の関連性（Answer Relevancy）の計算方法

RAGAS フレームワークでは、生成された回答が質問にどれだけ関連しているか（Answer Relevancy）を評価します。以下にその具体的な手順を説明します。

### 回答の関連性（Answer Relevancy）の計算方法

1. **質問の生成**:

   - まず、生成された回答から LLM（大規模言語モデル）を使用して、いくつかの潜在的な質問を生成します。
   - 使用するプロンプトの例：
     ```
     Generate a question for the given answer.
     answer: [answer]
     ```
   - このプロンプトを使用して、生成された回答に基づいた複数の質問 \( q_i \) を生成します。

2. **埋め込みの取得**:

   - 次に、生成された質問と元の質問の埋め込みベクトルを取得します。これには、OpenAI の API から利用可能な `text-embedding-ada-002` モデルなどを使用します。

3. **類似度の計算**:

   - 各生成された質問 \( q_i \) と元の質問 \( q \) との類似度を計算します。この類似度は、対応する埋め込みベクトル間のコサイン類似度として計算されます。

4. **回答関連性スコアの算出**:
   - 最終的な回答関連性スコア (AR) は、生成された全ての質問との類似度の平均として計算されます。
   - 数式で表すと、次のようになります：
     回答関連性スコア (AR) = (すべての類似度の合計) ÷ (生成された質問の数)

### 具体例

例えば、質問と回答が以下のような場合を考えます：

- 質問: 「映画『オッペンハイマー』の監督は誰で、J・ロバート・オッペンハイマー役を演じたのは誰ですか？」
- 回答: 「クリストファー・ノーランが映画『オッペンハイマー』を監督しました。キリアン・マーフィーが J・ロバート・オッペンハイマーを演じています。」

この回答から次のような潜在的な質問を生成します：

1. 「映画『オッペンハイマー』の監督は誰ですか？」
2. 「映画『オッペンハイマー』で J・ロバート・オッペンハイマーを演じたのは誰ですか？」

次に、元の質問と生成された各質問の埋め込みベクトルを取得し、それぞれのコサイン類似度を計算します。

例えば、類似度が次のように計算されたとします：

1. 類似度(元の質問, 質問 1) = 0.95
2. 類似度(元の質問, 質問 2) = 0.90

この場合、回答関連性スコア (AR) は次のように計算されます：

回答関連性スコア (AR) = (0.95 + 0.90) ÷ 2 = 0.925

このようにして、回答の関連性を定量的に評価することができます。

以上が、RAGAS フレームワークにおける回答の関連性（Answer Relevancy）の計算方法です。この方法を用いることで、生成された回答が質問にどれだけ適切に関連しているかを評価することができます。

# Context Relevancy (廃止予定)

評価の対象：検索モジュール

## RAGAS フレームワークにおけるコンテキスト関連性（Context Relevancy）の計算方法

RAGAS フレームワークでは、与えられた検索結果が質問にどれだけ関連しているか（Context Relevancy）を評価します。以下にその具体的な手順を説明します。

### コンテキスト関連性（Context Relevancy）の計算方法

1. **関連文の抽出**:

   - まず、与えられた検索結果から質問に関連する文を抽出します。この作業は、LLM（大規模言語モデル）を使用して行います。LLM に対するプロンプトの例は以下の通りです：
     ```
     Please extract relevant sentences from the provided context that is absolutely required to answer the following question. If no relevant sentences are found, or if you believe the question cannot be answered from the given context, return the phrase "Insufficient Information". While extracting candidate sentences you're not allowed to make any changes to sentences from given context.
     ```

2. **文の分割**:

   - 検索結果と LLM によって抽出された文を、それぞれの文単位に分割します。これは、文分割ツールを使用して行います。
   - 例えば、`pysbd`ライブラリを使用して文を分割します：

     ```python
     seg = pysbd.Segmenter(language="en", clean=False)

     def sent_tokenize(text: str) -> List[str]:
         sentences = seg.segment(text)
         assert isinstance(sentences, list)
         return sentences
     ```

3. **スコアの計算**:
   - 抽出された関連文の数を元の検索結果の文の数で割り、関連性スコアを算出します。
   - 数式で表すと、次のようになります：
     コンテキスト関連性スコア (CR) = (抽出された関連文の数) ÷ (元の検索結果の全文の数)
   - これにより、関連性スコアは 0 から 1 の範囲で評価されます。

### 具体例

例えば、質問と検索結果および抽出された文が以下のような場合を考えます：

- 質問: 「アルベルト・アインシュタインについて教えてください。」
- 検索結果: 「アルベルト・アインシュタイン（1879 年 3 月 14 日 - 1955 年 4 月 18 日）は、ドイツ生まれの理論物理学者で、広く認められた史上最も偉大で影響力のある科学者の一人です。相対性理論の開発で最もよく知られていますが、量子力学にも重要な貢献をしました。彼の質量とエネルギーの等価性の公式 E = mc^2 は『世界で最も有名な方程式』と呼ばれています。彼は 1921 年に物理学でノーベル賞を受賞しました。」
- 抽出された文: 「アルベルト・アインシュタインは 1879 年 3 月 14 日に生まれ、ドイツ生まれの理論物理学者で、史上最も偉大で影響力のある科学者の一人とされています。彼は 1921 年に物理学でノーベル賞を受賞しました。」

この場合、検索結果の文を分割すると、次のようになります：

1. 「アルベルト・アインシュタイン（1879 年 3 月 14 日 - 1955 年 4 月 18 日）は、ドイツ生まれの理論物理学者で、広く認められた史上最も偉大で影響力のある科学者の一人です。」
2. 「相対性理論の開発で最もよく知られていますが、量子力学にも重要な貢献をしました。」
3. 「彼の質量とエネルギーの等価性の公式 E = mc^2 は『世界で最も有名な方程式』と呼ばれています。」
4. 「彼は 1921 年に物理学でノーベル賞を受賞しました。」

抽出された文の数は 2、元の検索結果の文の数は 4 です。この場合、コンテキスト関連性スコア (CR) は次のように計算されます：

コンテキスト関連性スコア (CR) = 2 ÷ 4 = 0.5

このようにして、検索結果の関連性を定量的に評価することができます。

以上が、RAGAS フレームワークにおけるコンテキスト関連性（Context Relevancy）の計算方法です。この方法を用いることで、検索結果が質問に対してどれだけ関連しているかを評価することができます。

# Context Recall

評価の対象：検索モジュール

## RAGAS フレームワークにおけるコンテキストリコール（Context Recall）の計算方法

RAGAS フレームワークでは、検索結果が基準となる正解（ground truth）にどの程度関連しているかを測定する指標です。以下にその具体的な手順を説明します。

### コンテキストリコール（Context Recall）の計算方法

1. **ステートメントの分類**:

   - まず、基準となる正解（ground truth）の各文を、与えられた検索結果に基づいて分類します。各文が検索結果に基づいているかどうかを「Yes」または「No」で二値分類します。
   - 使用するプロンプトの例：
     ```
     Given a context, and an answer, analyze each sentence in the answer and classify if the sentence can be attributed to the given context or not. Use only "Yes" (1) or "No" (0) as a binary classification. Output json with reason.
     ```

2. **分類結果の集計**:

   - 各文の分類結果を集計し、検索結果に基づいている文の数（TP）と基づいていない文の数（FN）を数えます。

3. **コンテキストリコールスコアの算出**:
   - 最終的なコンテキストリコールスコア (CR) は、検索結果に基づいている文の数を全体の文の数で割ったものとして計算されます。
   - 数式で表すと、次のようになります：
     コンテキストリコールスコア (CR) = (検索結果に基づいている文の数) ÷ (全体の文の数)

### 具体例

例えば、質問と検索結果および回答が以下のような場合を考えます：

- 質問: 「アルベルト・アインシュタインについて教えてください。」
- 検索結果: 「アルベルト・アインシュタイン（1879 年 3 月 14 日 - 1955 年 4 月 18 日）は、ドイツ生まれの理論物理学者で、広く認められた史上最も偉大で影響力のある科学者の一人です。相対性理論の開発で最もよく知られていますが、量子力学にも重要な貢献をしました。彼の質量とエネルギーの等価性の公式 E = mc^2 は『世界で最も有名な方程式』と呼ばれています。彼は 1921 年に物理学でノーベル賞を受賞しました。」
- 回答: 「アルベルト・アインシュタインは 1879 年 3 月 14 日に生まれ、ドイツ生まれの理論物理学者で、史上最も偉大で影響力のある科学者の一人とされています。彼は 1921 年に物理学でノーベル賞を受賞しました。彼は 1905 年に 4 本の論文を発表しました。」

この回答を次のように分類します：

1. 「アルベルト・アインシュタインは 1879 年 3 月 14 日に生まれ、ドイツ生まれの理論物理学者で、史上最も偉大で影響力のある科学者の一人とされています。」 - Yes
2. 「彼は 1921 年に物理学でノーベル賞を受賞しました。」 - Yes
3. 「彼は 1905 年に 4 本の論文を発表しました。」 - No（検索結果に基づいていない）

分類結果に基づいて、検索結果に基づいている文の数（TP）は 2、全体の文の数は 3 です。

この場合、コンテキストリコールスコア (CR) は次のように計算されます：

コンテキストリコールスコア (CR) = 2 ÷ 3 ≈ 0.67

このようにして、生成された回答が与えられた検索結果にどれだけ正確に基づいているかを定量的に評価することができます。

以上が、RAGAS フレームワークにおけるコンテキストリコール（Context Recall）の計算方法です。この方法を用いることで、生成された回答が与えられた検索結果にどれだけ忠実であるかを評価することができます。

# Context Precision

評価の対象：検索モジュール

## RAGAS フレームワークにおけるコンテキスト精度（Context Precision）の計算方法

RAGAS フレームワークでは、与えられた検索結果が質問に対してどれだけ有用であるか（Context Precision）を評価します。以下にその具体的な手順を説明します。

### コンテキスト精度（Context Precision）の計算方法

1. **有用性の判定**:

   - まず、与えられた検索結果が質問に対して有用であるかどうかを判定します。LLM（大規模言語モデル）を使用して、検索結果が有用かどうかを二値分類します。
   - 使用するプロンプトの例：
     ```
     Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as "1" if useful and "0" if not with json output.
     ```

2. **検索結果の有用性の評価**:

   - 各検索結果の有用性を評価し、関連する理由を記述します。判定結果は "1"（有用）または "0"（無用）で出力されます。

3. **平均精度スコアの算出**:
   - 各検索結果の判定結果に基づいて、平均精度スコアを計算します。具体的には、有用と判定された検索結果の数を全体の検索結果の数で割ります。
   - 数式で表すと、次のようになります：
     平均精度スコア (AP) = (有用と判定された検索結果の数) ÷ (全体の検索結果の数)

### 具体例

例えば、質問と検索結果および回答が以下のような場合を考えます：

- 質問: 「アルベルト・アインシュタインについて教えてください。」
- 検索結果: 「アルベルト・アインシュタイン（1879 年 3 月 14 日 – 1955 年 4 月 18 日）は、ドイツ生まれの理論物理学者で、広く認められた史上最も偉大で影響力のある科学者の一人です。彼は相対性理論を開発し、量子力学にも重要な貢献をしました。彼は 1921 年に物理学でノーベル賞を受賞しました。」
- 回答: 「アルベルト・アインシュタインは 1879 年 3 月 14 日に生まれたドイツ生まれの理論物理学者で、1921 年に物理学でノーベル賞を受賞しました。」

この場合、LLM を使用して検索結果の有用性を判定します：

1. 「アルベルト・アインシュタイン（1879 年 3 月 14 日 – 1955 年 4 月 18 日）は、ドイツ生まれの理論物理学者で、広く認められた史上最も偉大で影響力のある科学者の一人です。」 - 1（有用）
2. 「彼は相対性理論を開発し、量子力学にも重要な貢献をしました。」 - 1（有用）
3. 「彼は 1921 年に物理学でノーベル賞を受賞しました。」 - 1（有用）

全ての検索結果が有用と判定された場合、平均精度スコア (AP) は次のように計算されます：

平均精度スコア (AP) = 3 ÷ 3 = 1.0

このようにして、与えられた検索結果が質問に対してどれだけ有用であるかを定量的に評価することができます。

以上が、RAGAS フレームワークにおけるコンテキスト精度（Context Precision）の計算方法です。この方法を用いることで、検索結果が質問に対してどれだけ関連しているかを評価することができます。

# Context Utilization

評価の対象：検索モジュール

## RAGAS フレームワークにおける コンテキスト利用（Context Utilization） の計算方法

RAGAS フレームワークでは、与えられた検索結果が質問に対する回答にどれだけ利用されたか（Context Utilization）を評価します。以下にその具体的な手順を説明します。

### コンテキスト利用（Context Utilization） の計算方法

1. **有用性の判定**:

   - まず、与えられた検索結果が質問に対して有用であるかどうかを判定します。LLM（大規模言語モデル）を使用して、検索結果が有用かどうかを二値分類します。
   - 使用するプロンプトの例：
     ```
     Given question, answer and context verify if the context was useful in arriving at the given answer. Give verdict as "1" if useful and "0" if not with json output.
     ```

2. **検索結果の有用性の評価**:

   - 各検索結果の有用性を評価し、関連する理由を記述します。判定結果は "1"（有用）または "0"（無用）で出力されます。

3. **利用スコアの算出**:
   - 各検索結果の判定結果に基づいて、利用スコアを計算します。具体的には、有用と判定された検索結果の数を全体の検索結果の数で割ります。
   - 数式で表すと、次のようになります：
     利用スコア (CU) = (有用と判定された検索結果の数) ÷ (全体の検索結果の数)

### 具体例

例えば、質問と検索結果および回答が以下のような場合を考えます：

- 質問: 「アルベルト・アインシュタインについて教えてください。」
- 検索結果: 「アルベルト・アインシュタイン（1879 年 3 月 14 日 – 1955 年 4 月 18 日）は、ドイツ生まれの理論物理学者で、広く認められた史上最も偉大で影響力のある科学者の一人です。彼は相対性理論を開発し、量子力学にも重要な貢献をしました。彼は 1921 年に物理学でノーベル賞を受賞しました。」
- 回答: 「アルベルト・アインシュタインは 1879 年 3 月 14 日に生まれたドイツ生まれの理論物理学者で、1921 年に物理学でノーベル賞を受賞しました。」

この場合、LLM を使用して検索結果の有用性を判定します：

1. 「アルベルト・アインシュタイン（1879 年 3 月 14 日 – 1955 年 4 月 18 日）は、ドイツ生まれの理論物理学者で、広く認められた史上最も偉大で影響力のある科学者の一人です。」 - 1（有用）
2. 「彼は相対性理論を開発し、量子力学にも重要な貢献をしました。」 - 1（有用）
3. 「彼は 1921 年に物理学でノーベル賞を受賞しました。」 - 1（有用）

全ての検索結果が有用と判定された場合、利用スコア (CU) は次のように計算されます：

利用スコア (CU) = 3 ÷ 3 = 1.0

このようにして、与えられた検索結果が質問に対する回答にどれだけ利用されたかを定量的に評価することができます。

### Context Utilization と Context Precision の違い

Context Utilization は、検索結果が実際に回答に利用されたかどうかを評価します。一方、Context Precision は、検索結果が質問に対してどれだけ有用であるかを評価します。

以上が、RAGAS フレームワークにおける Context Utilization の計算方法です。この方法を用いることで、検索結果が質問に対する回答にどれだけ利用されたかを評価することができます。

# Answer Semantic Similarity

評価の対象：パイプライン全体

## RAGAS フレームワークにおける回答の意味的類似性（Answer Semantic Similarity）の計算方法

RAGAS フレームワークでは、生成された回答が基準となる正解ととどれだけ意味的に類似しているか（Answer Semantic Similarity）を評価します。以下にその具体的な手順を説明します。

### 回答の意味的類似性（Answer Semantic Similarity）の計算方法

1. **埋め込みの取得**:

   - まず、生成された回答と基準となる正解との埋め込みベクトルを取得します。

2. **正規化**:

   - 各埋め込みベクトルを正規化します。正規化は、ベクトルをそのノルムで割ることで行います。
   - 正規化されたベクトルを取得するために、次のように計算します：
     ```
     embedding_normalized = embedding / norm
     ```

3. **類似度の計算**:

   - 正規化された埋め込みベクトル間のコサイン類似度を計算します。コサイン類似度は、二つのベクトルの内積として計算されます。
   - コサイン類似度を計算するために、次のようにします：
     ```
     similarity = embedding_1_normalized @ embedding_2_normalized.T
     ```

4. **意味的類似性スコアの算出**:
   - 最終的な意味的類似性スコア (SS) は、計算されたコサイン類似度そのものです。
   - 必要に応じて、しきい値を設定し、スコアをバイナリにマッピングすることも可能です。

### 具体例

例えば、基準となる正解とと生成された回答が以下のような場合を考えます：

- 基準となる正解と: 「クリストファー・ノーランが映画『オッペンハイマー』を監督しました。キリアン・マーフィーが J・ロバート・オッペンハイマーを演じています。」
- 生成された回答: 「クリストファー・ノーランが映画『オッペンハイマー』を監督し、キリアン・マーフィーが主演しています。」

この場合、各回答の埋め込みベクトルを取得し、それを正規化します。その後、正規化されたベクトル間のコサイン類似度を計算します。

例えば、類似度が次のように計算されたとします：

1. 基準となる正解との埋め込みベクトルと生成された回答の埋め込みベクトルの類似度 = 0.95

この場合、回答の意味的類似性スコア (SS) は 0.95 となります。

このようにして、生成された回答が基準となる正解ととどれだけ意味的に類似しているかを定量的に評価することができます。

以上が、RAGAS フレームワークにおける回答の意味的類似性（Answer Semantic Similarity）の計算方法です。この方法を用いることで、生成された回答が基準となる正解ととどれだけ意味的に関連しているかを評価することができます。

# Answer Corectness

評価の対象：パイプライン全体

## RAGAS フレームワークにおける回答の正確性（Answer Correctness）の計算方法

RAGAS フレームワークでは、生成された回答がどれだけ正確であるか（Answer Correctness）を評価します。以下にその具体的な手順を説明します。

### 回答の正確性（Answer Correctness）の計算方法

1. **ステートメントの分類**:

   - まず、生成された回答と基準となる正解（ground truth）の各文を分類します。分類は以下の三つのカテゴリに分けられます：
     - TP（True Positive）：生成された回答の文が正解と一致する場合
     - FP（False Positive）：生成された回答の文が正解と一致しない場合
     - FN（False Negative）：正解に含まれているが、生成された回答に含まれていない場合
   - 使用するプロンプトの例：

     ```
     Given a ground truth and an answer statements, analyze each statement and classify them in one of the following categories:

     - TP (true positive): statements that are present in answer that are also directly supported by the one or more statements in ground truth,
     - FP (false positive): statements present in the answer but not directly supported by any statement in ground truth,
     - FN (false negative): statements found in the ground truth but not present in answer.

     Each statement can only belong to one of the categories. Provide a reason for each classification.
     ```

2. **分類結果の集計**:

   - 各文の分類結果を集計し、TP、FP、FN の数を数えます。

3. **F1 スコアの計算**:

   - F1 スコアは、正確性の評価に使用される指標であり、次のように計算されます：
     F1 スコア = TP ÷ (TP + 0.5 × (FP + FN))
   - TP が 0 の場合、F1 スコアは 0 となります。

4. **意味的類似性スコアの計算**:

   - 生成された回答と正解の間の意味的類似性も評価されます。これは、別の指標として計算され、全体のスコアに加重平均として組み込まれます。

5. **総合スコアの算出**:
   - F1 スコアと意味的類似性スコアを組み合わせて、最終的な正確性スコアを算出します。デフォルトでは、F1 スコアが 75%、意味的類似性スコアが 25%の重みを持ちます。
   - 数式で表すと、次のようになります：
     総合スコア = (0.75 × F1 スコア) + (0.25 × 意味的類似性スコア)

### 具体例

例えば、質問と回答、正解が以下のような場合を考えます：

- 質問: 「太陽は何によって動力を得ていますか？その主な機能は何ですか？」
- 回答: 「太陽は核分裂によって動力を得ています。太陽の主な機能は太陽系に光を提供することです。」
- 正解: 「太陽は水素原子がヘリウムに融合する核融合によって動力を得ています。この核融合プロセスは大量のエネルギーを放出します。このエネルギーは熱と光を提供し、地球上の生命に不可欠です。」

この場合、LLM を使用して文の分類を行います：

1. 「太陽は核分裂によって動力を得ています。」 - FP
2. 「太陽の主な機能は太陽系に光を提供することです。」 - TP

正解に含まれているが、生成された回答に含まれていない文は次の通りです：

1. 「太陽は水素原子がヘリウムに融合する核融合によって動力を得ています。」 - FN
2. 「この核融合プロセスは大量のエネルギーを放出します。」 - FN

分類結果に基づいて、TP は 1、FP は 1、FN は 2 です。この場合、F1 スコアは次のように計算されます：

F1 スコア = 1 ÷ (1 + 0.5 × (1 + 2)) = 1 ÷ 2 = 0.5

次に、意味的類似性スコアが計算されます（ここでは仮に 0.6 とします）。

最終的な正確性スコアは次のように計算されます：

総合スコア = (0.75 × 0.5) + (0.25 × 0.6) = 0.525

このようにして、生成された回答の正確性を定量的に評価することができます。

以上が、RAGAS フレームワークにおける回答の正確性（Answer Correctness）の計算方法です。この方法を用いることで、生成された回答がどれだけ正確であるかを評価することができます。

### 注釈

- F1 スコアは、適合率（Precision）と再現率（Recall）の調和平均であり、正確性の評価に広く使用される指標ですが、FP と FN の重み付けが同じであれば分ける必要がない。
- 意味類似性 スコアは、Answer Semantic Similarity と同じもので、F1 スコア 0.75、意味類似性スコア 0.25 で加重平均される。

# 考察とまとめ

RAGAS のソースを GPT4o に読んでもらって解説してもらったが、Context recall の解説が間違っていた。  
手直しをして他のもある程度見直したため、上記をもとに検討可能と考える。

## 各指標の計算式に関する考察

### 安定性について

冒頭で、Faithfulnesss の結果が安定しないと記述したが、これは指標の計算方法から検索結果や基準となる回答のサイズの影響が大きいと考えられる。  
指標の多くは、検索結果や回答文を分割して、それぞれの文に対して 0,1 で評価して評価合計を件数で割るという方法で計算されるため、文章のサイズが小さいと評価が安定しない。

- 安定性が低い指標
  Faithfulnesss, Context Relevancy, Context Recall, Context Precision

### 指標が計測する対象について

生成された回答と検索結果との関連性を計測する指標など、それぞれの指標が計測する対象は異なる。  
指標は以下の 3 つに分けられる。それぞれ

- 検索結果から回答を生成する部分
  生成 AI モデルと、プロンプトの調整
- 質問から検索結果を取得する部分
  検索ロジックと検索元データの改善
- パイプライン全体
  生成 AI モデル、検索ロジック、検索元データの改善

### 指標のまとめ

| 指標                       | 説明                                                           | 対象       | 正解の要否 | 安定性 |
| -------------------------- | -------------------------------------------------------------- | ---------- | ---------- | ------ |
| Faithfulnesss              | 生成された回答が与えられた検索結果にどれだけ忠実であるか       | 生成       | 不要       | 低     |
| Answer relevancy           | 生成された回答が質問にどれだけ関連しているか                   | 生成、検索 | 不要       | 中     |
| Context Relevancy          | 与えられた検索結果が質問にどれだけ関連しているか               | 検索       | 不要       | 低     |
| Context Recall             | 検索結果が基準となる正解にどの程度関連しているか               | 検索       | 必要       | 低     |
| Context Precision          | 与えられた検索結果が質問に対してどれだけ有用であるか           | 検索       | 不要       | 低     |
| Context Utilization        | 与えられた検索結果が質問に対する回答にどれだけ利用されたか     | 生成、検索 | 不要       | 中     |
| Answer Semantic Similarity | 生成された回答が基準となる正解とどれだけ意味的に類似しているか | 全体       | 必要       | 高     |
| Answer Correctness         | 生成された回答がどれだけ正確であるか                           | 全体       | 必要       | 中     |

## テスト段階で利用する指標

全体の評価ができ、安定性が高い Answer Semantic Similarity を利用する。

### 基本的な指標

- Answer Semantic Similarity

### 参考指標

- Answer Correctness

→ 　 Answer Correctness 　は、Answer Semantic Similarity の内容も利用した総合的な評価であるため。
　 F1 スコアとの加重平均を　 5 分 5 分にしたい場合、Answer Correctness ✕ 2 ＋ Answer Semantic Similarity ÷ 3 とする。

### チューニング時に検討する指標

Answer Semantic Similarity 　の結果が思わしくない場合、その他の指標を参考にどの部分を修正するかを検討する。

## カットーバー後に利用できる指標

基準となる正解（ground truth）がなくても利用できる指標は以下の通り。  
これらの指標を利用してモニタリングを行い、改善活動に役立てる。

- Faithfulnesss
- Answer relevancy
- Context Relevancy
- Context precision
- Context Utilization
